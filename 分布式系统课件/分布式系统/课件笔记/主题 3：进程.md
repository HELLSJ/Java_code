## 目录

- 线程
- 虚拟化
- 客户端
- 服务器
- 代码迁移

## 线程

### 线程简介

#### 核心思想

在物理处理器之上，通过软件构建虚拟处理器：

- **处理器**：操作系统为执行程序创建多个虚拟处理器，每个虚拟处理器运行不同程序。操作系统通过进程表跟踪虚拟处理器，表中条目存储 CPU 寄存器值、内存映射、打开文件、计费信息、权限等，构成进程上下文。处理器提供一组指令，并能自动执行一系列这些指令。
- **线程**：与进程类似，线程独立运行自身代码，但不追求高并发性。线程系统仅保留让多个线程共享 CPU 所需的必要信息，相当于可执行一系列指令的最小软件处理器。保存线程上下文即停止当前执行，并保留后续恢复所需的所有数据。
- **进程**：本质是操作系统虚拟处理器正在执行的程序，多个进程可同时共享同一 CPU。软件中的进程上下文类似硬件中的处理器上下文，进程是一个软件处理器，可运行一个或多个线程。运行线程即在该线程的上下文中执行指令。

线程是进程的更小组成部分，能提升分布式系统的效率和可管理性，通过聚焦维持系统平稳运行的必要功能，在不增加系统负载的前提下提升性能。

#### 上下文切换：上下文类型

- **处理器上下文**：CPU 执行一系列指令时需跟踪的基本信息，包括栈指针、地址寄存器、程序计数器等，是处理器完成工作和处理中断所需的最小值集合。
- **线程上下文**：与处理器上下文类似，但专为线程设计，包含寄存器和内存中存储的、用于执行线程指令的最小值集合，基于处理器上下文，增加了特定线程的状态细节。
- **进程上下文**：更为全面，包含线程上下文的所有内容，还添加了内存管理单元（MMU）寄存器值等。该上下文用于执行进程（可能包含多个线程），是进程运行状态的完整记录，确保所有操作平稳独立运行。

这三种上下文均帮助操作系统高效管理和切换不同任务：处理器上下文最基础，线程上下文增加线程特定细节，进程上下文最详细，涵盖进程运行所需的所有内容。

#### 上下文切换：关键观察

1. 线程共享同一地址空间，同一进程内的所有线程可访问相同内存，线程上下文切换可完全独立于操作系统完成。
2. 进程切换通常（在某种程度上）成本更高，因为需要操作系统参与。切换不同进程时，需陷入内核，增加额外开销。
3. 线程的创建和销毁比进程廉价得多，启动或停止线程的资源消耗更低，线程更轻量化，可快速便捷地创建和销毁。

#### 为何使用多线程：简单原因

- **避免不必要的阻塞**：单线程进程中，若发生阻塞系统调用，整个进程会陷入停滞。例如，电子表格程序需维护单元格间的关联关系，修改一个单元格后，所有依赖单元格需自动更新，可能触发大量计算。单线程环境下，计算期间难以接收用户输入，解决方案是至少设置两个控制线程：一个负责用户交互，一个负责更新电子表格，还可增加第三个线程在后台将电子表格备份到磁盘。
- **利用并行性**：在多处理器或多核系统上执行程序时，可利用并行性。每个线程分配到不同 CPU 或内核，共享数据存储在共享主内存中。设计合理时，这种并行性可实现透明化：进程在单处理器系统上也能正常运行，仅速度较慢。
- **避免进程切换**：大型应用可通过多个线程而非多个进程构建。

#### 避免进程切换：降低高昂的上下文切换成本

多线程在大型应用中也很实用。这类应用通常被开发为一组协作程序，每个程序由独立进程执行（这是 Unix 环境的典型方式），程序间通过进程间通信（IPC）机制协作，Unix 系统中常见的机制包括管道、消息队列和共享内存段。所有进程间通信机制的主要缺点是，通信通常需要相对大量的上下文切换：

1. 进程间通信需内核协调，进程通常需先从用户模式切换到内核模式，这涉及修改内存管理单元（MMU）中的内存映射和清空转换后备缓冲器（TLB）。
2. 在内核中，执行进程上下文切换。
3. 另一方需通过从内核模式切换回用户模式激活，这再次需要修改 MMU 映射和清空 TLB。

多线程的权衡：

- 线程运行时共享同一内存空间，若一个线程出错写入错误数据，可能影响所有其他线程。
- 操作系统和硬件不会主动保护线程使用的内存免受其他线程干扰。
- 线程切换比进程切换更快。

总结：尽管使用线程更快更高效，但存在一定风险，主要因线程共享内存空间且系统未提供相互保护机制。

#### 上下文切换的成本：如何衡量？

一种方法是使用时钟滴答，时钟滴答处理在操作系统中已基本普及。时钟中断器每 T 毫秒由时钟中断激活一次，T 通常在 0.5 到 20 毫秒之间，即每秒产生 2000 到 50 次中断。时钟中断器负责计时、CPU 使用率统计、发送告警信号、确保任务公平共享 CPU 等任务。通过改变中断频率，可观察其带来的开销。

#### 上下文切换的成本：以简单时钟中断器为例

- **直接成本**：执行上下文切换、运行中断器并切换回原任务所需的时间。
- **间接成本**：其他所有相关开销，主要是缓存破坏。对于英特尔处理器，上下文切换需约 0.5-1 微秒，中断器运行需约 0.5-7 微秒（取决于具体实现）。

直接开销并非主要问题，真正的影响在于上下文切换会严重破坏缓存，导致中断后的性能比中断前下降，这就是间接成本的体现。

#### 上下文切换的成本：缓存中数据的组织方式

- 缓存需要空间时，会淘汰最近最少使用（LRU）的数据块。
- 即使是简单的中断，也可能导致缓存发生大规模且持久的重组，影响应用程序性能。

缓存变化过程：

1. 中断前的缓存状态。
2. 中断后，数据块 D 被移除，留下空缺。
3. 再次访问数据块 D 时，它会被重新复制到缓存中，可能淘汰数据块 C，依此类推。

#### Python 简单示例 1

该示例演示如何使用`multiprocessing`包在 Python 中分离进程。核心是`sleeping`函数，让调用进程睡眠随机秒数。通过第 14 和 15 行的`Process`操作创建两个进程并启动，`join`操作让主进程等待新进程完成。

输出结果：

plaintext

```plaintext
46:34 eve 将要睡眠11秒
46:34 bob 将要睡眠18秒
46:45 eve 已醒来
46:52 bob 已醒来
```

#### Python 简单示例 2

启动两个名为`eve`和`bob`的进程，每个进程启动三个线程，均运行`sleeping`函数。与示例 1 的主要区别是存在共享变量`shared_x`。

代码：

python

运行

```python
import annotations
import multiprocessing as mp
import threading
import time
import random
import os

THREADS_PER_PROCESS: int = 3

def sleeping(name: str, shared: dict[str, int], lock: threading.Lock) -> None:
    t = time.gmtime()
    s = random.randint(1, 5)
    print(f"{t.tm_min:02d}:{t.tm_sec:02d} [{os.getpid()}] {name} 将要睡眠 {s} 秒")
    time.sleep(s)
    with lock:
        t = time.gmtime()
        shared["x"] += 1
        seen = shared["x"]
        print(f"{t.tm_min:02d}:{t.tm_sec:02d} [{os.getpid()}] {name} 已醒来，shared_x 现在为 {seen}")

def sleeper(proc_name: str, result_queue: mp.Queue) -> None:
    shared = {"x": random.randint(10, 99)}
    lock = threading.Lock()
    print(f"[{os.getpid()}] {proc_name} 启动，初始 shared_x = {shared['x']}")
    threads: list[threading.Thread] = []
    for i in range(THREADS_PER_PROCESS):
        th = threading.Thread(
            target=sleeping,
            args=(f"{proc_name}/t{i}", shared, lock),
            daemon=True
        )
        threads.append(th)
        th.start()
    for th in threads:
        th.join()
    print(f"[{os.getpid()}] {proc_name} 最终 shared_x = {shared['x']}")
    result_queue.put((proc_name, shared["x"]))

if __name__ == "__main__":
    mp.set_start_method("spawn", force=True)
    results: mp.Queue = mp.Queue()
    p1 = mp.Process(target=sleeper, args=("eve", results))
    p2 = mp.Process(target=sleeper, args=("bob", results))
    p1.start()
    p2.start()
    p1.join()
    p2.join()
    proc_results = dict([results.get(), results.get()])
    print(f"[Parent] 各进程的 shared_x 值：{proc_results}")
```

输出结果：

plaintext

```plaintext
[20700] eve 启动，初始 shared_x = 92
31:55 [20700] eve/t0 将要睡眠 1 秒
31:55 [20700] eve/t1 将要睡眠 4 秒
31:55 [20700] eve/t2 将要睡眠 5 秒
[9424] bob 启动，初始 shared_x = 32
31:55 [9424] bob/t0 将要睡眠 1 秒
31:55 [9424] bob/t1 将要睡眠 5 秒
31:55 [9424] bob/t2 将要睡眠 1 秒
31:56 [20700] eve/t0 已醒来，shared_x 现在为 93
31:56 [9424] bob/t0 已醒来，shared_x 现在为 33
31:56 [9424] bob/t2 已醒来，shared_x 现在为 34
31:59 [20700] eve/t1 已醒来，shared_x 现在为 94
32:00 [20700] eve/t2 已醒来，shared_x 现在为 95
[20700] eve 最终 shared_x = 95
32:00 [9424] bob/t1 已醒来，shared_x 现在为 35
[9424] bob 最终 shared_x = 35
[Parent] 各进程的 shared_x 值：{'eve': 95, 'bob': 35}
```

输出结果表明，`shared_x`在同一进程内的线程间共享，但在`eve`和`bob`两个进程间不共享，每个进程有自己的`shared_x`实例。`sleep`函数在 thread 和进程级别均有效，每个线程睡眠几秒，但宿主进程不会因`sleep`调用而阻塞，而是切换到其他线程运行（随后该线程也可能调用`sleep`）。这一机制对程序员透明，且线程是否在不同 CPU 内核上运行（若可用）也透明。即使每个进程启动 1000 个线程，计时依然准确。

#### 线程与操作系统

线程通常以线程包的形式提供，包含创建、销毁线程和管理同步工具的操作。线程包的实现主要有两种方式：

- 用户级线程库：完全在用户空间运行。
- 内核级线程：由内核处理线程及其调度。

##### 用户级线程库

优点：

- 线程的创建和销毁成本低，所有线程管理操作在用户地址空间完成，创建线程的主要成本是栈所需的内存，销毁线程主要是释放该内存，两种操作均较廉价。
- 线程切换速度极快，通常仅需几条指令，只需保存和重新加载 CPU 寄存器值，无需修改内存映射或进行 CPU 计费。线程上下文切换通常发生在需要同步时（如访问共享数据），但如前所述，上下文切换的大部分开销来自内存缓存破坏。

缺点：用户级线程在多对一线程模型（多个线程映射到一个可调度实体）中存在明显缺陷。若一个线程执行阻塞系统调用，整个进程（包括其所有线程）都会被阻塞。线程适合将大型应用构建为可同时运行的多个部分，但如果其中一部分因 I/O 阻塞，不应影响其他部分。线程常被用于同时处理多个外部事件，它们会阻塞并等待特定事件（如 I/O 操作），但如果内核无法单独看到或管理这些线程，就无法向它们正确发送事件信号，此时用户级线程作用有限。

##### 内核级解决方案

核心思想是在内核中实现线程包，所有操作均以系统调用的形式返回：

- 阻塞线程的操作不再是问题，内核会调度同一进程内的其他可用线程。
- 外部事件处理简单，内核（捕获所有事件）会调度与该事件关联的线程。
- 问题（或过去的问题）是效率损失，因为每个线程操作都需要陷入内核。

##### 总结：混合用户级和内核级线程

尝试将用户级和内核级线程整合为一个概念，但实际中，性能提升通常无法抵消复杂性增加带来的成本。

##### 混合用户级和内核级线程：核心思想

引入两级线程机制：内核线程可执行用户级线程。一个内核线程在单个进程的上下文中运行，每个进程可有多个内核线程。除管理内核线程外，运行时系统还提供用户级线程包，包含创建、销毁线程的常规操作和线程同步工具。关键是该线程包完全在用户空间实现，所有线程操作无需内核参与。

该线程包可由多个内核线程共享，每个内核线程可运行自己的用户线程。构建多线程应用时，需同时创建用户线程和内核线程，并将每个用户线程分配给一个内核线程，这种架构结合了两者的优点，兼具灵活性和效率。

##### 混合线程机制的工作原理（1/2）

- 当用户线程执行系统调用时，运行该用户线程的内核线程会被阻塞，但用户线程仍附着于该内核线程（类似用户线程排队等待，内核线程为其占位）。
- 内核可选择另一个附着有可运行用户线程的内核线程并启动运行，该用户线程可切换到用户空间中任何其他可运行的用户线程（类似在超市切换到移动更快的队伍）。
- 若用户线程调用阻塞操作，会切换到另一个可运行的用户线程，但仍附着于同一个内核线程（类似排队占位者暂时为他人占位，之后再回到原位置）。
- 若无可运行的用户线程，内核线程可能空闲甚至被内核移除（类似商店关门后，排队占位者可离开）。

##### 混合线程机制的工作原理（2/2）

- 这种机制确保进程的某一部分阻塞时，不会影响其他部分运行，使系统更高效灵活，尤其适合同时处理多个任务。
- 需注意，线程只是管理应用程序内并发执行的一种方式。实际中，许多应用由一组并发进程构建，通过操作系统提供的进程间通信工具协作。
- 使用进程而非线程的一大优势是数据空间分离，每个进程操作自己的数据，通过操作系统保护免受其他进程干扰。这种分离很重要，因为线程编程难度较大 —— 使用线程时，需自行管理共享数据的并发访问；而使用进程时，硬件会帮助保护数据空间，若进程尝试访问分配内存之外的数据，硬件会触发异常，由操作系统处理，这种保护在同一进程内的线程间不存在。

### 分布式系统中的线程

#### 客户端侧使用线程

多线程 Web 客户端通过以下方式隐藏网络延迟：

- Web 浏览器扫描传入的 HTML 页面时，若发现需要获取更多文件，每个文件由独立线程通过（阻塞）HTTP 请求获取，文件传入后，浏览器立即显示。

多线程客户端的 RPC 调用：

- 客户端同时执行多个远程过程调用（RPC），每个调用由不同线程处理，然后等待所有结果返回。
- 注意：若调用指向不同服务器，可能实现线性加速。

#### 多线程客户端：是否有效？

线程级并行度（TLP）：用\(C_i\)表示恰好有i个线程同时执行的时间比例，N为最大可同时执行的线程数。

实际测量：典型 Web 浏览器的 TLP 值在 1.5 到 2.5 之间，这意味着要充分利用并行性，客户端机器应配备 2 或 3 个内核或处理器，线程主要用于浏览器的逻辑组织。

#### 服务器侧使用线程

提升性能：

- 启动线程比启动新进程廉价，速度更快、资源消耗更少，可处理更多任务而不降低系统速度。
- 单线程服务器在多处理器系统上扩展性差。
- 与客户端类似，服务器可通过在处理前一个请求的同时处理下一个请求来隐藏网络延迟，保持系统高效运行，避免用户等待。

优化结构：

- 大多数服务器对 I/O 需求高，使用简单易懂的阻塞调用可简化结构。
- 多线程程序的控制流更简洁，通常代码量更小、更易理解。

#### 多线程流行的原因：架构设计

调度 / 工作线程模型（文件服务器）：文件服务器需要等待磁盘操作，可能导致进程阻塞。通常，服务器等待请求、处理请求并返回响应。

工作原理：

- 一个名为调度线程（dispatcher）的线程读取传入请求，客户端将请求发送到知名端点，调度线程检查请求后，将其交给空闲的工作线程（worker thread）处理。
- 这种设计不仅简化了服务器的工作流程，还确保服务器在其他线程等待磁盘或其他资源时，仍能处理新请求。在多核处理器上，线程可真正并行运行，大幅提升服务器效率。
- 当文件服务器中的工作线程对本地文件系统执行阻塞读取时，可能在等待磁盘数据时被挂起，此时其他线程会接管工作（可能是调度线程获取更多工作，或其他就绪的工作线程）。

若文件服务器不使用线程，可能作为单线程运行：服务器接收请求、完全处理后再处理下一个请求，等待磁盘期间不执行任何操作，无法处理其他客户端的请求。若服务器运行在专用机器上，等待磁盘时 CPU 会闲置，导致单位时间内处理的请求数量减少。而线程可提升性能，因为每个线程按常规顺序执行。

#### 单线程服务器：大型有限状态机

当请求到来时，单线程处理请求：若请求可从内存缓存满足，直接返回；否则，线程调度非阻塞（异步）磁盘操作，然后继续检查其他请求。磁盘操作完成后，操作系统通知线程，线程恢复处理原始请求，最终通过另一个非阻塞调用返回响应。

这种设计中，顺序处理的简洁性丧失：每次线程需要执行阻塞操作时，必须记录进度和所有额外状态信息，然后启动操作并转向其他任务（如处理新请求或已完成操作的后处理），若无工作可做，线程可能阻塞。这种设置模拟了多个线程及其栈，但更复杂，服务器像有限状态机一样，根据当前状态对事件做出反应。

关键结论：线程让我们在保持阻塞系统调用的顺序处理简洁性的同时，实现并行性。阻塞调用使编程更简单（类似普通过程调用），多个线程实现并行性、提升性能。单线程服务器更简单，但会显著限制单位时间内处理的请求数量。有限状态机方法通过非阻塞调用实现高并行性能，但编程和维护难度大。

三种模型总结：

- 多线程模型：平衡简洁性和性能，适合大多数服务器场景。
- 单线程模型：简洁但性能有限，适合请求处理简单、I/O 等待少的场景。
- 有限状态机模型：高性能但复杂，适合对性能要求极高的场景。

替代方案：使用多个进程组织服务器（多进程服务器），可更好地防止意外数据访问，但如果进程间需要大量通信，性能可能低于使用线程的方案。

---

## 虚拟化

### 虚拟化简介

- 线程和进程本质上是同时执行多个任务的方式，让程序看起来是并行运行的。在单处理器（或单核）计算机上，这种并行执行实际上是一种错觉 —— 由于只有一个 CPU，同一时间只能运行一个线程或进程的一条指令，但通过快速切换线程和进程，营造出并行的效果。
- 这种利用一个 CPU 模拟多个 CPU 的思想可扩展到其他资源，称为资源虚拟化。
- 虚拟化已存在数十年，但随着分布式计算机系统变得越来越普遍和复杂，其重要性日益凸显。

### 虚拟化的重要性

- 硬件和底层软件进化迅速，而中间件和应用程序等高层软件相对稳定，导致旧软件无法跟上其所依赖的平台更新。虚拟化通过允许旧接口在新平台上运行，使新平台立即兼容大量现有软件，解决了这一问题。
- 网络已无处不在，现代计算机几乎都连接到网络，这意味着系统管理员需要管理大量不同的服务器，每个服务器运行不同的应用程序，供客户端访问。虚拟化通过让每个应用程序在自己的虚拟机（可能带有自己的库和操作系统）上运行，简化了管理，所有虚拟机共享一个公共平台。
- 这种虚拟化提供了极高的可移植性和灵活性。例如，管理支持动态内容复制的内容分发网络（CDN）时，若边缘服务器支持虚拟化，可轻松动态复制整个站点（包括其运行环境），这种方法至今仍有效，可移植性是虚拟化在许多分布式系统中至关重要的主要原因之一。
- 虚拟化为代码提供了额外的隔离层，这在云计算中尤为重要，可确保单个故障或安全攻击不会影响整个系统。

### 虚拟化原理：模拟接口

- 实际中，每个分布式计算机系统都为高层软件提供编程接口，这些接口可以是 CPU 提供的基本指令集，也可以是大量应用程序编程接口（API）。
- 虚拟化的核心是扩展或替换现有接口，使其表现得像另一个系统。

### 模拟接口的层级

三种层级下的四种接口类型：

1. 指令集架构（ISA）：硬件和软件之间的接口，即机器指令集，分为：
    - 特权指令：仅允许操作系统执行。
    - 普通指令：任何程序均可执行。
2. 操作系统提供的系统调用：软件通过系统调用与硬件和系统资源交互。
3. 库调用（应用程序编程接口 API）：系统调用被隐藏在 API 之后，简化程序员的开发工作。
4. 虚拟化的核心思想是模拟这些接口的行为，使软件认为自己运行在某一类型的系统上，而实际运行在另一类型的系统上。

### 虚拟化的实现方式

三种虚拟化方式：

1. 进程虚拟机（Process VM）：
    
    - 创建运行时系统，提供一组抽象指令用于运行应用程序，这些指令可被解释（如在 Unix 系统上运行 Windows 应用程序）。
    - 这种情况下，模拟器还需模拟系统调用，专为单个进程设计，通过在操作系统之上运行解释器 / 模拟器实现。
2. 原生虚拟机监控器（Native VMM）：
    
    - 在原始硬件和软件之间构建一层，提供完整的硬件指令集，直接在硬件上实现。
    - 允许多个不同的客户操作系统在同一台机器上独立并发运行。
3. 托管虚拟机监控器（Hosted VMM）：
    
    - 原生虚拟机监控器需要管理对存储和网络等各种资源的访问，这意味着它必须实现设备驱动程序（类似操作系统）。
    - 托管虚拟机监控器运行在可信的宿主操作系统之上，可利用宿主操作系统提供的现有功能，通常需要特殊权限（而非作为普通应用程序运行）。
    - 这种托管方式在数据中心和云服务等现代分布式系统中很流行。

虚拟机的核心价值：

- 虚拟机对分布式系统的可靠性和安全性至关重要，可隔离整个应用程序及其运行环境，确保单个故障或安全攻击不会影响整个机器。
- 通过解耦硬件和软件，虚拟机提高了可移植性，便于将环境从一台机器迁移到另一台机器。

### 虚拟机深入：性能优化

细化架构：

- 特权指令：仅在用户模式下执行时，会触发陷入操作系统。
- 非特权指令：除特权指令外的其他指令。
- 特殊指令：
    - 控制敏感指令：可能影响机器配置（如修改重定位寄存器或中断表的指令）。
    - 行为敏感指令：效果部分取决于上下文（如 POPF 指令设置中断启用标志，但仅在系统模式下有效）。

### 虚拟化的必要条件

必要条件：对于任何传统计算机，若其敏感指令集是特权指令集的子集，则可构建虚拟机监控器。这意味着，若能在用户模式下捕获敏感指令，即可安全地让所有其他指令直接在硬件上运行。设计指令集时，若确保敏感指令均为特权指令，可大幅提高虚拟化效率。

问题：该条件并非总能满足。

- 流行的英特尔 x86 指令集有 17 条敏感指令不是特权指令，这些指令可在用户模式下运行而不触发操作系统陷入，但仍会影响操作系统对资源的管理。

解决方案：

- 解释所有指令。
- 包装非特权敏感指令，将控制权转移到虚拟机监控器（VMM）。
- 半虚拟化（Paravirtualisation）：修改客户操作系统，要么避免使用非特权敏感指令，要么使其变为非敏感指令（即修改上下文）。

### 容器

虚拟机允许需要特定操作系统环境（包括指令集和操作系统）的应用程序在不同平台上运行。然而，许多应用程序的指令集和操作系统稳定，但依赖特定的库和支持软件。在这种情况下，我们希望不同应用程序并排运行，每个应用程序拥有自己的环境，且互不干扰，这就是容器的用武之地。

容器的本质：

- 容器可视为一组二进制文件（也称为镜像）的集合，共同构成应用程序运行的软件环境。
- 最简单的理解方式是想象用户登录 Unix 系统时看到的内容：多个标准目录，包含可执行程序、库、文档等。

容器的简单实现：

- 为特定用例复制整个环境，并将其安装为根文件系统的子目录。容器内的应用程序仅能看到所需的库和依赖项，而其他容器内的应用程序看到自己的定制环境。
- 容器实际上虚拟化了应用程序的软件环境，允许其在自己的隔离空间中运行，同时与其他容器共享底层系统，便于管理和部署应用程序，避免冲突。

简单容器实现的局限性：

- 不同容器中的应用程序和进程需要相互隔离。
- 为每个容器复制整个环境效率极低，因为许多库和资源在容器间共享。
- 宿主容器的操作系统需要有效控制资源。

### 容器的核心机制

容器通过以下机制实现高效、隔离和可管理：

- 命名空间（Namespaces）：容器中的进程集合拥有自己的标识符视图。
- 联合文件系统（Union file system）：将多个文件系统以分层方式组合，仅最高层允许写操作（且属于容器的一部分）。
- 控制组（Control groups）：可对进程集合施加资源限制。

### 容器示例：PlanetLab

核心本质：

- 一个协作式分布式系统，由不同组织贡献的数百个节点组成，这些计算机形成服务器集群，每个节点均可进行访问、处理和存储操作。

问题：需要确保不同的分布式应用程序互不干扰，解决方案是虚拟化。

### PlanetLab 的基本架构

每个参与组织向项目捐赠一台或多台计算机（称为节点），这些节点供所有 PlanetLab 用户共享。

两个关键组件：

- 虚拟机监控器（VMM）：增强型 Linux 操作系统，支持容器，已调整为支持第二个组件 Vserver。
- Vserver：本质上是运行中的容器，可视为独立且受保护的环境，每个 Vserver 拥有自己的库、服务器版本和其他必要软件，这种隔离允许不同 Vserver 在同一物理机器上并排运行而不相互干扰。分布式应用程序被分配到分布在多台机器上的一组 Vserver。

### PlanetLab 的 Vserver 和切片（Slice）

核心本质：

- Linux VMM 确保 Vserver 之间的隔离，不同 Vserver 中的进程同时独立运行，仅使用自己环境中可用的软件和程序。这种隔离非常严格，例如，不同 Vserver 中的两个进程可拥有相同的用户 ID，但这并不意味着它们来自同一用户。这种分离便于支持来自不同组织的用户，他们希望使用 PlanetLab 实验不同的分布式系统和应用程序。
- 为支持此类实验，PlanetLab 使用切片（slice），每个切片是一组 Vserver，每个 Vserver 运行在不同节点上。切片可视为虚拟服务器集群，由通过广域网连接的一组容器实现。

切片的资源管理：

- PlanetLab 资源管理的关键部分是节点管理器（node manager），每个节点都有自己的管理器（实现为独立 Vserver），其职责是在节点上创建其他 Vserver 并管理资源分配。
- 创建新切片时，每个节点运行切片创建服务（SCS），切片创建服务可联系节点管理器，请求创建 Vserver 并分配资源。重要的是，节点管理器无法通过网络直接联系，因此可专注于本地资源管理。
- 资源跟踪通过资源规范（resource specification）完成，指定特定时间段内分配的资源，包括磁盘空间、文件描述符、网络带宽、内存和 CPU 使用率。资源规范由全局唯一的 128 位标识符（称为资源权限，rcap）标识，节点管理器可通过 rcap 在本地表中查找相关资源规范。
- 资源与切片绑定，即使用资源需创建切片，每个切片与服务提供者关联（类似在 PlanetLab 上拥有账户）。

### 虚拟机在分布式系统中的应用

#### 虚拟机与云计算

三种云服务类型：

- 基础设施即服务（IaaS）：覆盖基础架构。
- 平台即服务（PaaS）：覆盖系统级服务。
- 软件即服务（SaaS）：包含实际应用程序。

IaaS 中的虚拟化：虚拟化是基础设施即服务的核心。云服务提供商不租赁物理机器，而是租赁虚拟机（VM），该 VM 可能与其他客户共享物理机器。虚拟化的优势在于，由于几乎完全隔离，可为客户营造拥有专用物理机器的错觉。然而，这种隔离并不完美，因为物理资源仍被共享，有时可能导致明显的性能下降。

---

## 客户端

### 客户端：网络用户界面

客户端 - 服务器交互需区分应用级和中间件级解决方案：客户端机器的主要任务之一是帮助用户与远程服务器交互，大致有两种方式：

1. 对于每个远程服务，客户端机器有单独的对应程序，可通过网络联系该服务。例如，用户智能手机上的日历需要与远程（可能共享的）日历同步，此时由应用级协议处理同步。
2. 提供便捷的用户界面，直接访问远程服务，客户端机器仅作为终端，无需本地存储。这种方法与应用程序无关，在网络用户界面中，所有处理和存储均在服务器上完成。随着互联网连接和移动设备使用的普及，瘦客户端方法变得流行，且便于系统管理。

### 示例：X 窗口系统（X Window System）

#### 基本架构

X 窗口系统（常简称为 X）是最古老且仍广泛使用的网络用户界面之一，用于控制位图终端（包括显示器、键盘和鼠标等指针设备），除支持传统台式计算机和工作站外，还适用于平板电脑和智能手机上的触摸屏，可视为操作系统中控制终端的部分。

X 的核心是 X 内核（X kernel），包含所有终端特定的设备驱动程序，通常高度依赖硬件。

#### X 客户端与服务器交互

X 内核提供控制屏幕和捕获键盘、鼠标事件的底层接口，该接口通过名为 Xlib 的库提供给应用程序。

X 的特别之处在于，X 内核和 X 应用程序不必在同一台机器上。X 提供 X 协议（应用级通信协议），允许 Xlib 实例与 X 内核交换数据和事件。例如，Xlib 可向 X 内核发送创建 / 关闭窗口、设置颜色、定义光标类型等请求，X 内核则通过发送事件数据包响应键盘和鼠标输入等本地事件。

#### X 的优化：实际观察

- 应用程序使用 X 提供的特定显示命令操作显示，这些命令通常通过网络发送，由 X 内核执行。理想情况下，为 X 编写的应用程序应将应用逻辑与用户界面命令分离，但实际情况往往并非如此。
- 许多应用逻辑和用户交互紧密耦合，应用程序会向 X 内核发送大量请求，并等待响应后再继续，这种同步行为会影响性能，尤其在延迟较高的广域网上。

#### X 的优化：替代方案

1. 重新设计 X 协议（如 NX）：NX 客户端是允许个人计算机作为终端与远程 Unix 机器通信的程序，核心工作之一是通过减小 X 消息大小降低带宽消耗。消息分为固定部分（标识符）和可变部分，多个消息可能具有相同标识符和相似数据，可仅发送消息间的差异，接收方通过跟踪标识符即可轻松解码，这种方法可将带宽使用率降低多达 1000 倍，允许 X 在低带宽链路上运行。
2. 让应用程序在像素级别控制远程显示（也称为远程桌面控制）：显示位图的变化通过网络发送到显示器，在本地帧缓冲区更新。虚拟网络计算（VNC）是知名示例，这种方式需要复杂的编码技术以避免带宽问题。

### 客户端：虚拟桌面环境

#### 逻辑发展

随着云计算的发展和云应用的增多，将云转变为用户的虚拟桌面环境变得合理，用户只需通过客户端软件访问该桌面。谷歌是最早通过 Chrome OS 实现这一理念的公司之一：

- 核心思想：让浏览器提供本地桌面界面，除浏览器外，还有多个独立应用程序，最终均与云端对应程序连接，这种架构类似现代智能手机。
- 随着应用程序向浏览器扩展程序转变，浏览器正逐渐接管操作系统的用户界面功能，变得更像桌面环境，用户可在其中运行连接到云的不同应用程序。

#### 网页浏览器的内部结构（1/5）

Chrome 浏览器是复杂的软件，代码量超过 2500 万行（与 Linux 内核相当）。Web 刚出现时，仅包含简单的 HTML 页面，如今不仅有高级标记语言，还有大量交互工具和客户端脚本语言。

Chrome 的核心是资源加载器（resource loader），负责从 Web 服务器获取内容，通常先获取 HTML 文件，然后通过独立线程并行建立连接，获取页面中引用的其他内容。资源加载器需要部分分析 HTML 文件，确定需要获取的其他内容，大部分分析工作由构建文档对象模型（DOM）的组件完成，DOM 本质上是 HTML 文件的树形表示。

#### 网页浏览器的内部结构（2/5）

DOM 表示页面结构，但实际样式信息来自单独的文档（例如，指定所有段落的颜色和字体）。样式信息单独分析后添加到 DOM 中，创建渲染树（render tree），该树包含下一步所需的所有信息：确定每个元素的显示位置，包括计算 DOM 不同部分的几何区域和决定换行位置（对于浮动图像或多列等元素，这一过程可能很复杂）。

#### 网页浏览器的内部结构（3/5）

布局确定后，绘制组件（painting component）接管，创建绘制操作程序（如`drawRectangle(x, y, height, width)`），这些操作由光栅化（rasterisation）过程执行，填充屏幕上每个像素的细节（包括颜色）。光栅化还处理嵌入式图像，确保图像的每个像素正确显示。DOM 实际上被分解为多个层，每个层单独光栅化后，合成（compositing）为屏幕上显示的最终图像，合成器（compositor）处理滚动等用户交互。

#### 网页浏览器的内部结构（4/5）

现代浏览器还包含处理脚本（如 JavaScript）的组件。JavaScript 是流行的客户端 Web 应用程序脚本语言，代码以浏览器权限运行，相对安全。在浏览器内运行代码的优势在于，让用户感觉像是在本地桌面运行应用程序。

#### 网页浏览器的内部结构（5/5）

渲染网页是高度复杂的过程，许多部分（如层光栅化）并行执行，有时使用 GPU 等专用处理器。现代网页浏览器使用线程和进程不仅是为了更好的结构和组织，也是为了高效渲染。例如，Chrome 中，渲染由独立进程处理，包括 HTML 解析、样式处理、布局制作、绘制和合成，光栅化可能使用 GPU，并通过消息传递与主进程通信。每个浏览器标签有自己的渲染器进程，为提高安全性，每个渲染器在单独的沙箱中运行，防止直接与底层操作系统通信。

### 客户端软件：面向分布透明性（1/2）

客户端软件不仅包括用户界面，客户端 - 服务器应用程序中的部分处理和数据也通常在客户端侧处理。嵌入式系统（如 ATM、收银机、条形码阅读器和电视机顶盒）中存在一类特殊的客户端软件，在这些系统中，与本地处理和通信功能相比，用户界面仅占软件的一小部分。除用户界面和应用相关软件外，客户端软件还包含实现分布透明性的组件。理想情况下，客户端不应知晓自己正在与远程进程通信；而出于性能和正确性原因，服务器侧的分布透明性通常较低。

分布透明性的实现：

- 访问透明性：通常通过从服务器提供的接口定义生成客户端存根（stub）实现。存根提供与服务器相同的接口，但隐藏机器架构和通信差异，将本地调用转换为发送到服务器的消息，反之亦然，将服务器消息转换为返回值，如同调用常规过程。
- 位置 / 迁移透明性：处理位置、迁移和重定位透明性的方法有很多，使用良好的命名系统至关重要，通常需要客户端软件协作。例如，客户端已连接到服务器时，若服务器位置变化，可直接通知客户端，客户端的中间件可隐藏服务器的新网络位置，并在必要时重新绑定到服务器，最坏情况下，客户端应用程序可能会注意到暂时的性能下降。
- 复制透明性：许多分布式系统使用客户端侧解决方案实现复制透明性。例如，在具有复制服务器的分布式系统中，请求可转发到每个副本，客户端软件收集所有响应后，将单个响应传递给客户端应用程序。
- 故障透明性：客户端中间件通常处理与服务器的通信故障屏蔽，例如，可反复尝试连接服务器，或多次尝试后切换到另一服务器，有时还会返回先前会话中缓存的数据（类似 Web 浏览器无法连接到服务器时的行为）。

### 客户端软件：面向分布透明性（2/2）

客户端软件的功能远不止处理用户界面，还在分布式系统的处理、通信和透明性维护中发挥关键作用。

---

## 服务器

### 服务器：总体架构

#### 基本模型

服务器是代表一组客户端实现特定服务的进程，等待客户端的传入请求，处理请求后，继续等待下一个请求。

两种基本类型：

- 迭代服务器（Iterative server）：服务器亲自处理请求，必要时向请求客户端返回响应。
- 并发服务器（Concurrent server）：不亲自处理请求，而是将其交给独立线程或其他进程，然后立即等待下一个传入请求。多线程服务器是并发服务器的示例，另一种实现是为每个新传入请求创建新进程（Unix 系统中常用），处理请求的线程或进程负责向请求客户端返回响应。

观察：并发服务器已成为标准，因为它们可轻松同时处理多个请求，尤其适用于可能阻塞的操作（如访问磁盘或与其他服务器通信）。

#### 联系服务器（1/2）

客户端始终将请求发送到服务器机器上的端点（也称为端口），每个服务器在特定端点上监听请求。但客户端如何知道服务的端点？

观察：大多数服务绑定到特定端口。例如，处理互联网 FTP 请求的服务器始终在 TCP 端口 21 上监听，Web 的 HTTP 服务器始终在 TCP 端口 80 上监听，这些端口由互联网号码分配机构（IANA）分配。有了这些预分配的端点，客户端只需知道服务器机器的网络地址，可通过命名服务查找该地址。

常见服务端口示例：

|服务|端口|描述|
|---|---|---|
|ftp-data|20|文件传输（默认数据端口）|
|ftp|21|文件传输（控制端口）|
|telnet|23|远程登录|
|smtp|25|简单邮件传输协议|
|www|80|Web（HTTP）|

#### 联系服务器（2/2）

动态分配端点的两种方法：并非所有服务都需要预分配端点，例如，时间服务器可能使用本地操作系统动态分配的端点。这种情况下，客户端需先查找端点，解决方案如下：

1. 每个运行服务器的机器上运行特殊守护进程（daemon），跟踪本地服务器实现的每个服务的当前端点，守护进程自身在知名端点上监听。客户端先联系守护进程请求端点，再联系特定服务器。
2. 将端点与特定服务关联很常见，但为每个服务单独设置服务器可能浪费资源。例如，典型 Unix 系统中，许多服务器同时运行，大多数被动等待客户端请求。与其跟踪多个被动进程，不如让单个超级服务器（superserver）监听与特定服务关联的每个端点，效率更高。

两种实现流程：

- 基于守护进程：客户端先向守护进程请求端点，守护进程从端点表中查询后返回，客户端再联系特定服务器。
- 基于超级服务器：客户端直接向超级服务器请求服务，超级服务器创建对应服务器并移交请求，客户端与特定服务器继续交互。

#### 带外通信：问题与解决方案

服务器设计中的一个问题是如何处理中断。例如，用户向 FTP 服务器上传大文件时，发现上传的是错误文件，想要取消上传，有以下解决方案：

解决方案 1：使用单独的端口传输紧急数据

- 服务器有独立的线程 / 进程处理紧急消息，同时（以较低优先级）监听正常数据端点，服务器在单独的控制端点上监听带外数据。
- 紧急消息到来时，关联请求被暂停。
- 注意：需要操作系统支持基于优先级的调度。

解决方案 2：利用传输层功能

- 通过原始请求使用的同一连接发送带外数据（例如，TCP 允许在同一连接中传输紧急消息）。
- 可通过操作系统信号技术捕获紧急消息。

#### 服务器与状态：无状态服务器（1/2）

- 无状态服务器不保留客户端的状态信息，可在不通知任何客户端的情况下更改自身状态。例如，Web 服务器是无状态的，仅响应传入的 HTTP 请求（如上传文件或更常见的获取文件），处理请求后，立即忘记客户端。Web 服务器管理的文件集合可随时更改，无需通知客户端。
- 许多无状态设计中，服务器实际上会保留一些客户端信息，但关键是若这些信息丢失，不会影响服务器提供的服务。例如，Web 服务器通常记录所有客户端请求，日志可用于决定是否复制某些文档及复制位置，若日志丢失，仅可能导致性能不佳，但服务仍可继续。
- 无状态设计的一种特殊形式是服务器维护 “软状态”（soft state），即服务器承诺为客户端保留某些状态信息，但仅在有限时间内，超时后服务器丢弃该信息并恢复默认行为。例如，服务器可能承诺在有限时间内通知客户端更新，超时后，客户端需主动轮询服务器获取更新。软状态方法源自计算机网络中的协议设计，也可应用于服务器设计。

#### 服务器与状态：无状态服务器（2/2）

处理请求后，绝不保留关于客户端状态的准确信息：

- 不记录文件是否已打开（访问后直接关闭）。
- 不承诺失效客户端缓存。
- 不跟踪客户端。

后果：

- 客户端和服务器完全独立。
- 减少因客户端或服务器崩溃导致的状态不一致。
- 可能损失性能（例如，服务器无法预测客户端行为，如预取文件块）。

#### 问题：面向连接的通信是否适合无状态设计？

答案：面向连接的通信（如使用 TCP）意味着客户端和服务器之间存在持续连接，该连接本身固有地携带一些状态信息（如连接状态和传输数据）。

在真正的无状态设计中，服务器处理请求后不保留任何关于客户端的信息，不应记住客户端或连接的任何细节，但面向连接的通信要求服务器跟踪连接状态，这似乎与无状态理念矛盾。

然而，我们可以实现半无状态设计：服务器可独立处理每个请求，不依赖先前的交互，即使存在持续连接。服务器不记录文件是否已打开等细节，也不承诺失效客户端缓存，仅将每个请求视为首次接收。

尽管纯无状态性和面向连接的通信可能无法完美契合，但我们可设计服务器以最小化状态依赖，独立处理请求，这与无状态模型非常接近。

#### 服务器与状态：有状态服务器

跟踪客户端状态：

- 服务器维护一些持久信息，不再需要时需显式删除。例如，允许客户端保留文件本地副本进行更新的文件服务器，会维护（客户端，文件）条目表，跟踪哪个客户端对哪个文件有更新权限，以及该文件的最新版本。
- 记录文件已打开的状态，以便进行预取。
- 知晓客户端缓存的数据，允许客户端保留共享数据的本地副本。

观察：这种方法可从客户端角度提高读写操作的性能，性能提升通常是有状态设计的显著优势。但缺点是，若服务器崩溃，需恢复其（客户端，文件）条目表，以确保处理文件的最新更新。通常，有状态服务器必须恢复崩溃前的完整状态，这会引入大量复杂性。而在无状态设计中，恢复无需特殊措施，服务器只需重启并等待客户端请求即可。

### 对象服务器（1/2）

与传统服务器不同，对象服务器本身不提供特定服务，而是托管提供各种服务的对象。因此，服务器的主要工作是管理这些对象并处理远程客户端的请求，通过添加或删除对象，可轻松添加或删除服务。

对象服务器可视为对象 “居住” 的地方，对象包含两个主要部分：表示状态的数据和定义方法的代码，管理方式可能不同。有些服务器中，每个对象可能有自己的线程；而在其他服务器中，每个对象请求可能使用新线程。

激活策略（收到调用请求时采取的操作）：

- 对象的代码和数据位于何处？
- 使用哪种线程模型？
- 是否保留对象的修改状态（若有）？

### 对象服务器（2/2）

对象适配器（Object adapter）：为管理激活策略，服务器使用对象适配器，可视为强制执行特定激活策略的软件。这些适配器是通用工具，开发人员可根据对象需求配置。

对象适配器的特点：

- 一个对象适配器可控制一个或多个对象，由于服务器可能需要同时支持具有不同激活策略的对象，因此可拥有多个适配器，请求到来时，会定向到相应的适配器。
- 对象适配器无需知道所管理对象的特定接口，具有灵活性和通用性，其职责是从请求中提取对象引用，然后传递给正确的对象。
- 适配器不直接将请求发送到对象，而是交给该对象的服务器侧存根（也称为骨架，skeleton），存根基于对象的接口定义创建，处理请求后，调用对象的相应方法。

对象适配器的价值：使用对象适配器可灵活高效地管理和调用分布式系统中的对象，便于动态处理各种服务。

### 服务器集群

#### 三层架构：常见组织（1/2）

核心架构：逻辑交换机（可能多个）→ 应用 / 计算服务器 → 分布式文件 / 数据库系统。

客户端请求流程：客户端发送请求，逻辑交换机分发请求，应用 / 计算服务器处理请求，分布式文件 / 数据库系统提供数据支持。

关键组件：

- 第一层（逻辑交换机）：路由客户端请求，形式多样。例如，传输层交换机接收传入的 TCP 连接请求，将其转发到集群中的某台服务器；Web 服务器处理传入的 HTTP 请求，将部分请求传递给应用服务器进一步处理，收集结果后返回 HTTP 响应。
- 第二层（应用 / 计算服务器）：企业环境的服务器集群中，通常有专门用于应用处理的服务器。若瓶颈是存储访问而非计算能力，这些服务器可能不需要高性能；但在需要大量计算能力的集群计算场景中，应用服务器通常是设计用于处理密集型处理任务的高性能机器。

#### 三层架构：常见组织（2/2）

第三层（数据处理服务器）：由文件服务器和数据库服务器等数据处理服务器组成，根据集群需求，这些服务器可能运行在专门优化的机器上，以支持高速磁盘访问和大型服务器端数据缓存。

并非所有服务器集群都遵循三层架构，有时集群中的每台机器都有自己的本地存储，将应用和数据处理合并到单个服务器中，形成两层架构。例如，流媒体服务器集群中，常见两层系统，每台机器作为专用媒体服务器，同时处理应用和数据处理任务。

#### 请求处理（1/3）

观察：第一层通常处理所有通信，若由第一层处理集群的所有进出通信，可能导致瓶颈。

解决方案：TCP 移交（TCP handoff）：交换机可将连接移交给选定的服务器，使所有响应直接传递给客户端，无需经过交换机。

#### 请求处理（2/3）

TCP 移交的工作原理：交换机收到 TCP 连接请求后，首先确定处理该请求的最佳服务器，将请求数据包转发给该服务器。服务器向请求客户端返回确认，但在携带 TCP 段的 IP 数据包头部的源字段中插入交换机的 IP 地址。这种地址重写是必要的，因为客户端期望从交换机收到响应，而非从未听说过的任意服务器。显然，TCP 移交实现需要修改操作系统。当响应远大于请求时（如 Web 服务器），TCP 移交尤为有效。

#### 请求处理（3/3）

TCP 移交的负载均衡：交换机在服务器间分配负载方面发挥重要作用，通过决定请求的转发目的地，确定哪个服务器处理请求的后续处理。交换机可采用的最简单负载均衡策略是轮询（round robin）：每次从列表中选择下一台服务器转发请求。当然，交换机必须跟踪已将 TCP 连接移交给哪台服务器（至少直到连接断开）。事实证明，维护此状态并移交属于同一 TCP 连接的后续 TCP 段，可能会降低交换机的速度。

#### 服务器分布在互联网上

观察：将服务器分布在互联网上可能引入管理问题，这可通过使用单个云服务提供商的数据中心在很大程度上规避。

请求调度（若本地性很重要）：常用方法：使用 DNS。

1. 客户端通过 DNS 查找特定服务，请求中包含客户端的 IP 地址。
2. DNS 服务器跟踪所请求服务的副本服务器，返回最接近客户端的服务器地址。

客户端透明性：为使客户端不感知分布，让 DNS 解析器代表客户端工作，但问题是解析器可能离实际客户端很远。

#### Akamai CDN 的简化版本（1/5）

核心流程：DNS 系统 → 常规 DNS 系统 → CDN → CDN 边缘缓存服务器 ← 源服务器。

关键步骤：

1. 客户端查找`www.example.com`。
2. 常规 DNS 系统将域名解析为`www.example.com.akamai.net`，返回给客户端。
3. CDN 的 DNS 系统返回最佳边缘缓存服务器的地址。
4. 客户端联系边缘缓存服务器获取内容，若边缘缓存服务器无所需内容，从源服务器（`org-www.example.com`）获取并缓存，再返回给客户端。

重要说明：视频服务器离客户端越近，越容易提供高质量流，这种方法被基于云的内容分发网络（CDN）采用。CDN 是利用广域集群的重要分布式系统组。

#### Akamai CDN 的简化版本（2/5）

核心思想：存在一台托管网站所有文档的源服务器，为使源服务器的内容由 CDN 托管，Akamai 首先确保`www.example.com`的域名解析为`www.example.com.akamai.net`（该域名指向 Akamai CDN 的边缘服务器），为仍能访问源服务器，其域名需更改为`org-www.example.com`。

#### Akamai CDN 的简化版本（3/5）

详细流程：

1. 客户端首先查找常规域名，但被重定向到 Akamai 的解析器。
2. Akamai 的域名解析器查找最适合为客户端提供服务的边缘服务器，返回其网络地址。
3. 客户端联系边缘服务器，边缘服务器知晓源服务器的新域名。
4. 若请求的内容不在边缘服务器的缓存中，边缘服务器从源服务器获取文档，缓存后将请求的内容返回给客户端。

#### Akamai CDN 的简化版本（4/5）

自适应重定向策略：通过正确重定向客户端，CDN 可控制客户端感知的性能，同时考虑全局系统性能（例如，避免将请求发送到负载过重的服务器）。当向做出重定向决策的进程提供系统当前行为信息时，可应用这种自适应重定向策略。

#### Akamai CDN 的简化版本（5/5）

缓存的高级功能：Akamai 的缓存通常足够复杂，不仅可存储被动数据，还可迁移源服务器的大部分应用代码。

---

## 代码迁移

### 代码迁移的原因（1/2）

1. 负载分布：
    
    核心思想是，若将进程从负载重的机器迁移到负载轻的机器，可提高整体系统性能。

- 确保数据中心的服务器充分负载（例如，避免能源浪费）。
- 通过将计算靠近数据所在位置，最小化通信（如移动计算）。

2. 灵活性：根据需要将代码迁移到客户端：
    
    客户端和服务器通信时，客户端获取特定于服务的客户端侧代码，避免预安装软件，提高动态配置能力。

### 代码迁移的原因（2/2）

3. 隐私和安全：
    
    许多情况下，由于各种原因（通常是法律原因），数据无法迁移到其他位置，解决方案是将代码迁移到数据所在位置。

示例：联邦机器学习：

- 本地参与者拥有本地数据，训练本地模型并生成更新。
- 中央服务器收集所有本地更新，聚合为新模型，再分发给本地参与者。

### 代码迁移模型

客户端 - 服务器计算中，代码、执行状态和资源段均位于服务器，执行后通常仅修改服务器的执行状态（用星号标记）。

四种迁移模型：

1. 发送者启动的远程评估（Sender-initiated remote evaluation）：客户端将代码迁移到服务器，代码在服务器上执行，修改服务器的执行状态。
2. 按需代码（Code-on-demand）：接收者启动的方案，客户端从服务器获取代码，执行后修改客户端侧的执行状态，并操作客户端的资源。
3. 移动代理（Mobile agents）：通常采用发送者启动的方法，将代码和执行状态从客户端迁移到服务器，操作客户端和服务器的资源，运行移动代理通常会修改相关执行状态。

### 强迁移与弱迁移

对象组件：

- 代码段：包含实际代码。
- 资源段：包含进程所需的外部资源引用（如文件、打印机、设备、其他进程）。
- 执行状态：包含执行对象代码的线程上下文。

弱迁移（Weak mobility）：仅迁移代码和资源段（并重启执行），相对简单（尤其若代码可移植），分为代码推送（code shipping）和代码拉取（code fetching）。

强迁移（Strong mobility）：迁移所有组件（包括执行状态），分为：

- 迁移（Migration）：将整个对象从一台机器迁移到另一台机器。
- 克隆（Cloning）：启动克隆体，使其处于相同的执行状态。

### 异构系统中的代码迁移

主要问题：

- 目标机器可能不适合执行迁移的代码。
- 进程 / 线程 / 处理器上下文的定义高度依赖本地硬件、操作系统和运行时系统。
- 分布式系统构建在异构平台集合上，每个平台有自己的操作系统和机器架构。

解决方案：在不同平台上实现抽象机器：

- 解释型语言（本质上拥有自己的虚拟机）。
- 虚拟机监控器。
- 依赖（进程）虚拟机，直接解释源代码（如脚本语言）或解释编译器生成的中间代码（如 Java）。

迁移整个计算环境：不仅迁移进程，还迁移整个计算环境。通过虚拟机迁移，可将计算环境与底层系统解耦，并迁移到另一台机器。

### 虚拟机迁移

三种迁移镜像的方法：

1. 将内存页推送到新机器，并重发迁移过程中后续修改的内存页。
2. 停止当前虚拟机，迁移内存，然后在新机器上启动虚拟机。
3. 让新虚拟机根据需要拉入新页面：进程立即在新虚拟机上启动，按需复制内存页。

### 虚拟机迁移的性能

问题：完整迁移可能需要数十秒，迁移期间，服务将完全不可用数秒。好消息是，仅在迁移完成的停机时间后，响应时间才会显著增加。

虚拟机迁移期间的响应时间测量：迁移停机时间是影响响应时间的关键因素。